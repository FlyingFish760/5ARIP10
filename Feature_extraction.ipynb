{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Team_project\\DCASE_data\\dev_gearbox\n",
      "Directory already downloaded: F:\\Team_project\\DCASE_data\\dev_gearbox\n",
      "All data downloaded\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "# Download a zipfile that contains dev_gearbox of DCASE_2022 dataset \n",
    "###################################################################################\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Data directory. Change this to your own directory\n",
    "# You need 946.4 MB to store all data.\n",
    "dir_data = os.path.abspath(\"F:\\Team_project\\DCASE_data\")\n",
    "\n",
    "# URL to retrieve dev_gearbox data. \n",
    "url_dev_gearbox = 'https://zenodo.org/record/6355122/files/dev_gearbox.zip?download=1'\n",
    "dir_dev_gearbox = os.path.join(dir_data, \"dev_gearbox\")\n",
    "\n",
    "# Download and extraction function\n",
    "def download_extract(url: str):\n",
    "    # Create a temp directory to download into\n",
    "    with tempfile.TemporaryDirectory(dir=dir_data, prefix=\"download_\") as dir_temp:\n",
    "        print(f'Downloading: {url}')\n",
    "        zip_path = os.path.join(dir_temp, 'download.zip')\n",
    "        urlretrieve(url, zip_path, lambda n, size, total: sys.stdout.write(f'\\rProgress: {n*size/total*100:.2f} %'))\n",
    "        sys.stdout.write('\\n')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        print(f'Unpacking archive.')\n",
    "        shutil.unpack_archive(zip_path, dir_data)\n",
    "\n",
    "# Create the data directory (if it does not exist)\n",
    "os.makedirs(dir_data, exist_ok=True)\n",
    "\n",
    "# Check if the dev_gearbox directory have been downloaded and extracted\n",
    "for dir, url in [(dir_dev_gearbox, url_dev_gearbox)]:\n",
    "    print(dir)\n",
    "    if not os.path.isdir(dir):\n",
    "        # Download the required files\n",
    "        print(f'Directory does not exist: {dir}')\n",
    "        download_extract(url)\n",
    "    else:\n",
    "        print(f'Directory already downloaded: {dir}')\n",
    "\n",
    "# Done!\n",
    "print(f'All data downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Team_project\\DCASE_data\\dev_gearbox\\train\\features\n",
      "Feature extracting: F:\\Team_project\\DCASE_data\\dev_gearbox\\train\n",
      "Feature extracting sub-directory: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\torchaudio\\functional\\functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m             tensor_name \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)   \u001b[39m#delete \".\" in the original file name in oder avoid name error\u001b[39;00m\n\u001b[0;32m     42\u001b[0m             tensor_name \u001b[39m=\u001b[39m tensor_name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mwav\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m             torch\u001b[39m.\u001b[39;49msave(specgram, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dir_train_feature, tensor_name))\n\u001b[0;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFeature extraction done\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    440\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    442\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\serialization.py:668\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[0;32m    667\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n\u001b[1;32m--> 668\u001b[0m zip_file\u001b[39m.\u001b[39mwrite_record(name, storage\u001b[39m.\u001b[39mdata_ptr(), num_bytes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "# Extract features of DCASE dataset\n",
    "###################################################################################\n",
    "\n",
    "\n",
    "dir_train = os.path.join(dir_dev_gearbox, \"train\")\n",
    "feature = 'Melspectrogram'\n",
    "\n",
    "# Directories for features of datasets\n",
    "dir_train_feature = os.path.join(dir_train, \"features\")\n",
    "\n",
    "# Run feature extraction of data\n",
    "for dir_file, dir_feature in [(dir_train, dir_train_feature)]:\n",
    "    print(dir_feature)\n",
    "    # Check if the directory already exists\n",
    "    if os.path.isdir(dir_feature):\n",
    "        print(f'Features directory already exists: {dir_feature}')\n",
    "        continue\n",
    "\n",
    "    print(f'Feature extracting: {dir_file}')\n",
    "\n",
    "    # Walk though the directory and extract features of each file \n",
    "    for root,_,files in  os.walk( dir_file ):\n",
    "        if len(files) == 0:\n",
    "            continue\n",
    "\n",
    "        print(f'Feature extracting sub-directory: {root.replace(dir_file, \"\")}')\n",
    "\n",
    "        # Create the directory\n",
    "        root_feature = root.replace(dir_file, dir_feature)\n",
    "        os.makedirs(root_feature, exist_ok=True)\n",
    "\n",
    "        for f in files:\n",
    "            if not f.endswith('.wav'):\n",
    "                continue\n",
    "\n",
    "            # extract and save Melspectrogram features \n",
    "            path_original = os.path.join(root,f)\n",
    "            waveform,sample_rate = torchaudio.load(path_original)        \n",
    "            specgram = torchaudio.transforms.MelSpectrogram()(waveform)\n",
    "            tensor_name = f.replace(\".\", \"\")   #delete \"dot\" in the original file name in oder avoid name error\n",
    "            tensor_name = tensor_name.replace(\"wav\", \".pt\")\n",
    "            torch.save(specgram, os.path.join(dir_train_feature, tensor_name))\n",
    "\n",
    "\n",
    "print(f'Feature extraction done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
