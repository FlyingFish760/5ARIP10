{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[41.         30.66594202 89.          9.         28.        ]]\n",
      "\n",
      " [[40.6        36.4450271  93.          0.         29.        ]]\n",
      "\n",
      " [[31.4        15.86946754 54.         11.         36.        ]]\n",
      "\n",
      " [[66.6        18.8        88.         33.         72.        ]]\n",
      "\n",
      " [[60.         11.027239   77.         49.         54.        ]]\n",
      "\n",
      " [[45.8        35.59438158 92.         13.         25.        ]]\n",
      "\n",
      " [[45.2        27.83810338 89.         12.         30.        ]]\n",
      "\n",
      " [[33.8        13.01383879 57.         18.         31.        ]]\n",
      "\n",
      " [[61.8        32.6521056  94.         22.         77.        ]]\n",
      "\n",
      " [[42.         32.82072516 88.          9.         28.        ]]\n",
      "\n",
      " [[54.4        31.42355804 88.         15.         71.        ]]\n",
      "\n",
      " [[31.2        25.8178233  75.          7.         17.        ]]\n",
      "\n",
      " [[65.8        29.12318664 96.         28.         84.        ]]\n",
      "\n",
      " [[42.4        33.97999411 88.          4.         44.        ]]\n",
      "\n",
      " [[48.2        24.18594633 88.         15.         50.        ]]\n",
      "\n",
      " [[54.2        35.97443537 88.          6.         77.        ]]\n",
      "\n",
      " [[46.6        38.91323682 96.         11.         22.        ]]\n",
      "\n",
      " [[59.4        11.87602627 79.         42.         57.        ]]\n",
      "\n",
      " [[64.2        23.86126568 97.         40.         50.        ]]\n",
      "\n",
      " [[30.2        24.45730975 73.          0.         23.        ]]\n",
      "\n",
      " [[42.8        33.8431677  84.          3.         29.        ]]\n",
      "\n",
      " [[42.2        24.17767565 79.         14.         50.        ]]\n",
      "\n",
      " [[35.         13.60882067 53.         17.         32.        ]]\n",
      "\n",
      " [[60.8        29.67423125 90.         12.         80.        ]]\n",
      "\n",
      " [[28.8        27.78056875 81.          0.         17.        ]]\n",
      "\n",
      " [[45.6        19.58162404 73.         22.         38.        ]]\n",
      "\n",
      " [[77.2        15.03861696 96.         62.         67.        ]]\n",
      "\n",
      " [[69.4        24.27014627 99.         27.         77.        ]]\n",
      "\n",
      " [[67.8        21.72003683 93.         37.         75.        ]]\n",
      "\n",
      " [[40.6        29.26841301 95.         11.         33.        ]]\n",
      "\n",
      " [[68.         22.88230758 96.         40.         73.        ]]\n",
      "\n",
      " [[65.2        29.52558213 90.          8.         72.        ]]\n",
      "\n",
      " [[50.         27.61883415 89.         25.         30.        ]]\n",
      "\n",
      " [[56.4        26.74023186 85.         13.         62.        ]]\n",
      "\n",
      " [[49.2        35.18749778 94.          4.         33.        ]]\n",
      "\n",
      " [[33.6        30.89077532 91.          7.         22.        ]]\n",
      "\n",
      " [[34.4        27.11899703 76.          3.         32.        ]]\n",
      "\n",
      " [[54.4        20.01599361 74.         30.         68.        ]]\n",
      "\n",
      " [[32.8        30.74020169 75.          2.         13.        ]]\n",
      "\n",
      " [[56.4        31.09083466 93.          5.         52.        ]]\n",
      "\n",
      " [[44.8         9.4318609  62.         34.         42.        ]]\n",
      "\n",
      " [[67.8        21.89429149 94.         32.         69.        ]]\n",
      "\n",
      " [[31.6        18.9377929  50.          1.         44.        ]]\n",
      "\n",
      " [[53.6        26.36361129 83.         18.         63.        ]]\n",
      "\n",
      " [[53.2        25.50607771 88.         15.         55.        ]]\n",
      "\n",
      " [[21.8        20.86528217 50.          0.          9.        ]]\n",
      "\n",
      " [[27.2        24.9351158  68.          4.         14.        ]]\n",
      "\n",
      " [[57.4        20.48999756 90.         38.         44.        ]]\n",
      "\n",
      " [[32.         23.84114091 75.          9.         20.        ]]\n",
      "\n",
      " [[53.2        15.6        81.         39.         49.        ]]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # generate a random matrix\n",
    "\n",
    "# 设置种子\n",
    "np.random.seed(10)\n",
    "# 生成矩阵\n",
    "mt1 = np.random.randint(0, 100, size=250)\n",
    "\"\"\" splits = np.array_split(mt1, 50)\n",
    "print(splits)\n",
    "\"\"\"\n",
    "def extract_basics_split(data):\n",
    "    means = np.empty((1, 50))\n",
    "    stds = np.empty((1, 50))\n",
    "    maxs = np.empty((1, 50))\n",
    "    mins = np.empty((1, 50))\n",
    "    medians = np.empty((1, 50))\n",
    "\n",
    "    splits = np.array_split(data, 50)\n",
    "    \n",
    "    for j in range(len(splits)):\n",
    "        means[0, j] = np.mean(splits[j])\n",
    "        stds[0, j] = np.std(splits[j])\n",
    "        maxs[0, j] = np.max(splits[j])\n",
    "        mins[0, j] = np.min(splits[j])\n",
    "        medians[0, j] = np.median(splits[j])\n",
    "\n",
    "    features = np.array([means, stds, maxs, mins, medians])\n",
    "\n",
    "    features = features.T\n",
    "    return features\n",
    "\n",
    "features = extract_basics_split(mt1)\n",
    "print(features) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 5)\n"
     ]
    }
   ],
   "source": [
    "#Import libaries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.io import wavfile \n",
    "from scipy.signal import filtfilt, butter\n",
    "from pylab import *\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "#Import self-written functions\n",
    "from Denoise_Functions import *\n",
    "from features_functions import *\n",
    "\n",
    "#Get directories with data\n",
    "dir_gearbox = os.path.join(os.getcwd(), 'gearbox')\n",
    "dir_train = os.path.join(dir_gearbox, \"train\")\n",
    "dir_test = os.path.join(dir_gearbox, \"test\")\n",
    "\n",
    "# Extract anomoly files and normal files from the test set\n",
    "anom_files = []\n",
    "anom_sr = []\n",
    "anom_data = []\n",
    "anom_data_fft = []\n",
    "\n",
    "norm_files = []\n",
    "norm_sr = []\n",
    "norm_data = []\n",
    "norm_data_fft = []\n",
    "\n",
    "# make a list of all the files in the training data folder that contain section_00 in the name and volt_1.0 in the name\n",
    "for i in os.listdir(dir_test):\n",
    "    if 'anomaly' in i and 'section_00' in i and 'volt_1.0' in i:\n",
    "        anom_files.append(i)\n",
    "        # data, samplerate = librosa.load(dir_test + '/' + i,sr=16000)\n",
    "        samplerate, data = wavfile.read(dir_test + '\\\\' + i)\n",
    "        anom_sr.append(samplerate)\n",
    "        anom_data.append(data)\n",
    "\n",
    "        #Also store the fft data\n",
    "        data_fft_v1 = fft(data)\n",
    "        data_fft = 2.0/(data.shape[0]) * np.abs(data_fft_v1[0:data.shape[0]//2])\n",
    "        anom_data_fft.append(data_fft)\n",
    "\n",
    "    if 'normal' in i and 'section_00' in i and 'volt_1.0' in i:\n",
    "        norm_files.append(i)\n",
    "        # data, samplerate = librosa.load(dir_test + '/' + i,sr=16000)\n",
    "        samplerate, data = wavfile.read(dir_test + '\\\\' + i)\n",
    "        norm_sr.append(samplerate)\n",
    "        norm_data.append(data)\n",
    "\n",
    "        #Also store the fft data\n",
    "        data_fft_v1 = fft(data)\n",
    "        data_fft = 2.0/(data.shape[0]) * np.abs(data_fft_v1[0:data.shape[0]//2])\n",
    "        norm_data_fft.append(data_fft)\n",
    "\n",
    "# extract basic features\n",
    "anom_means, anom_stds, anom_maxs, anom_mins, anom_medians = extract_basics_split(anom_data)\n",
    "norm_means, norm_stds, norm_maxs, norm_mins, norm_medians = extract_basics_split(norm_data)\n",
    "\n",
    "# convert list objectives to numpy array form\n",
    "anom_means_arr = np.array(anom_means)\n",
    "anom_stds_arr = np.array(anom_stds)\n",
    "anom_maxs_arr = np.array(anom_maxs)\n",
    "anom_mins_arr = np.array(anom_mins)\n",
    "anom_medians_arr = np.array(anom_medians)\n",
    "norm_means_arr = np.array(norm_means)\n",
    "norm_stds_arr = np.array(norm_stds)\n",
    "norm_maxs_arr = np.array(norm_maxs)\n",
    "norm_mins_arr = np.array(norm_mins)\n",
    "norm_medians_arr = np.array(norm_medians)\n",
    "\n",
    "# create a matrix of size n_samples times n_features\n",
    "X_anom = np.stack([anom_means_arr, anom_stds_arr, anom_maxs_arr, anom_mins_arr, \n",
    "                         anom_medians_arr], axis=0).T\n",
    "\n",
    "X_norm = np.stack([norm_means_arr, norm_stds_arr, norm_maxs_arr, \n",
    "                         norm_mins_arr, norm_medians_arr], axis=0).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy  as np\n",
    "\n",
    "# define the fitness function\n",
    "def  calculate_fitness(individual , X):\n",
    "    # Convert  binary  string  to  boolean  mask\n",
    "    mask = np.array(list(individual), dtype=bool)\n",
    "    # Apply  mask to  dataset\n",
    "    X_masked = X[:, mask]\n",
    "    # Calculate  variance  of each  feature\n",
    "    variances = np.var(X_masked , axis =0)\n",
    "    # Calculate  fitness  as the  sum of  variances\n",
    "    fitness = np.sum(variances)\n",
    "    \n",
    "    return  fitness\n",
    "\n",
    "\n",
    "# define the genetic algorithm\n",
    "def genetic_algorithm(data, population_size, num_genes, calculate_fitness, mutation_rate, elitism_rate, num_generations):\n",
    "    # initialize the population\n",
    "    population = []\n",
    "    for i in range(population_size):\n",
    "        individual = [random.randint(0, 1) for j in range(num_genes)]\n",
    "        population.append(individual)\n",
    "        # print(population)\n",
    "\n",
    "    # run the evolution loop for num_generations\n",
    "    for generation in range(num_generations):\n",
    "        # evaluate the fitness of each individual in the population\n",
    "        fitness_values = [calculate_fitness(individual, data) for individual in population]\n",
    "\n",
    "        # select the fittest individuals for the next generation\n",
    "        num_elites = int(elitism_rate * population_size)\n",
    "        elites = sorted(range(len(population)), key=lambda i: fitness_values[i], reverse=True)[:num_elites]\n",
    "        next_generation = [population[i] for i in elites]\n",
    "\n",
    "        # breed new individuals to fill the rest of the next generation\n",
    "        while len(next_generation) < population_size:\n",
    "            parent1, parent2 = random.choices(population, weights=fitness_values, k=2)\n",
    "            child = [parent1[i] if random.random() < 0.5 else parent2[i] for i in range(num_genes)]\n",
    "            if random.random() < mutation_rate:\n",
    "                gene_to_mutate = random.randint(0, num_genes-1)\n",
    "                child[gene_to_mutate] = 1 - child[gene_to_mutate]\n",
    "            next_generation.append(child)\n",
    "\n",
    "        # replace the old population with the new generation\n",
    "        population = next_generation\n",
    "        # print(population)\n",
    "\n",
    "    # return the fittest individual found\n",
    "    return max(population, key=lambda individual: calculate_fitness(individual, data))\n",
    "\n",
    "data = X_anom\n",
    "population_size = 32   # 2 to the n_feature th, which means all the combination of features\n",
    "num_genes = 5\n",
    "mutation_rate=0.01\n",
    "elitism_rate=0.1\n",
    "num_generations=5\n",
    "\n",
    "features = genetic_algorithm(data, population_size, num_genes, calculate_fitness, mutation_rate=0.01, elitism_rate=0.1, num_generations=100)\n",
    "print(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
